# LAB for Audio Recognition and Audio Synthesis

[![Python](https://img.shields.io/badge/Python-3.9%2B-blue.svg)](https://www.python.org/)
[![PyTorch](https://img.shields.io/badge/PyTorch-2.5.1%2B-red.svg)](https://pytorch.org/)
[![Matplotlib](https://img.shields.io/badge/Matplotlib-3.1.1%2B-yellow.svg)](https://matplotlib.org/)
[![Torchaudio](https://img.shields.io/badge/Torchaudio-2.5.1%2B-orange.svg)](https://pytorch.org/audio)
[![Librosa](https://img.shields.io/badge/Librosa-0.10.2%2B-green.svg)](https://librosa.org/)

<!--
torch                              2.5.1+cu121
torchaudio                         2.5.1+cu121
torchsummary                       1.5.1
torchvision                        0.20.1+cu121
-->
> 서강대학교 CSE5109/CSEG109/AIE5109/AIEG109 과목의 실습 자료를 위한 저장소입니다.

## 실습 내용

### LAB 1: 기초 신호 처리 및 오디오 파일 다루기
- Numpy와 matplotlib를 이용한 기초 데이터 처리
- Python을 이용한 기초 신호 처리

### LAB 2: 딥러닝 기초 및 언어 모델
- PyTorch를 이용한 딥러닝 기초
- MLP를 이용한 간단한 언어 모델 구현
- 모델 학습 및 평가

### LAB 3: 음성 합성
- [Korean-FastSpeech2-Pytorch](https://github.com/HGU-DLLAB/Korean-FastSpeech2-Pytorch)
    - (Forked)[Korean-FastSpeech2-Pytorch](https://github.com/june-oh/Korean-FastSpeech2-Pytorch)
    - 위 저장소를 기반으로 한국어 음성 합성을 Colab에서 실행할 수 있도록 수정하였습니다.
- FastSpeech2 모델 학습 및 평가
- FastSpeech2 모델 추론

## 실습 노트북
1. [Lab 1 - Basic Audio File Handling](Lab_1_Basic_Numpy_and_Siganl_Processing.ipynb)
2. [Lab 2-0 - PyTorch and Deep Learning](LAB2_0_PyTorch_and_Deep_Learning.ipynb)
3. [Lab 2-1 - Language Model Exercise](LAB2_1_LM_Exercise.ipynb)
4. [Lab 3-1 - FastSpeech2 Training](LAB3_1_Fastspeech2_Train.ipynb)
5. [Lab 3-2 - FastSpeech2 Inference](LAB3_2_FastSpeech2_Inferene.ipynb)

## 필요 라이브러리
### 실습 환경
- colab
### 필요 라이브러리(Colab 환경에 설치돼 있음)
- numpy
- matplotlib 
- torch
- torchaudio

## 참고사항
- 각 실습은 Google Colab 환경에서 실행 가능하도록 구성되어 있습니다
- 실습 자료는 지속적으로 업데이트될 예정입니다
- 실습 종료 후 solution 노트북을 추가할 예정입니다


